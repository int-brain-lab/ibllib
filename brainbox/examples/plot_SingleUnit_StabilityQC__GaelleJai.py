
# CODE from Jai :
# https://github.com/int-brain-lab/ibllib/blob/f495abac5812fb7e5bb161418acfae71ee13d6a1/brainbox/plot/plot.py
#
#  Work on sessions:
#
# EPHYS:	mainenlab   ZM_2407	    2019-11-05  	Guido
#           Dual	3A	_iblrig_tasks_ephys_certification

import os
from pathlib import Path
import numpy as np
import brainbox as bb
import alf.io as aio
# import ibllib.ephys.spikes as e_spks
from oneibl.one import ONE
one = ONE()

need_load = bool(0)
probe = 'probe_00'  # must set probe name

if need_load:
    # This is only useful if you do not have the data accessible on the machine

    # -- GET EID FOR SPECIFIC SESSION
    # Check that each dataset type needed is present
    dataset_types = ['ephysData.raw.ap', 'spikes.times', 'clusters.depths']
    eid, sinfo = one.search(
        datasets=dataset_types,
        subjects='ZM_2407',
        date_range='2019-11-05',
        details=True)
    assert(len(eid) > 0), 'No EID found with those search terms'
    dtypes_session = one.list(eid)[0]
    if not set(dataset_types).issubset(set(dtypes_session)):
        missing_dtypes = [dt for dt in dataset_types if dt not in dtypes_session]
        raise ValueError('Missing datasets: ' + ','.join(missing_dtypes))

    # In case the above did not run,
    # you can find all sessions containing raw data by looking into sinfos:
    # eids, sinfos = one.search(
    #    datasets=['ephysData.raw.ap', 'spikes.times'], task_protocol='certification', details=True)
    
    # Set important directories from `eid`
    spikes_path = one.load(eid, dataset_types='spikes.amps', clobber=False, download_only=True)[0]
    alf_dir_part = np.where([part == 'alf' for part in Path(spikes_path).parts])[0][0]
    session_path = os.path.join(*Path(spikes_path).parts[:alf_dir_part])
    alf_dir = os.path.join(session_path, 'alf')
    alf_probe_dir = os.path.join(alf_dir, probe)
    ephys_file_dir = os.path.join(session_path, 'raw_ephys_data', probe)
    # Find 'ap' ephys file in `ephys_file_dir`
    for i in os.listdir(ephys_file_dir):
            if 'ap' in i and 'bin' in i:
                ephys_file_path = os.path.join(ephys_file_dir, i)
    # Ensure directories can be found
    assert os.path.isdir(ephys_file_dir) and os.path.isdir(alf_probe_dir) \
        and os.path.isabs(ephys_file_path), 'Directories set incorrectly'

else:
    ephys_file_path = '/Users/gaelle/Downloads/FlatIron/mainenlab/Subjects/ZM_2407/2019-11-05/003/raw_ephys_data/probe_00/_spikeglx_ephysData_probe00.raw_g0_t0.imec.ap.cbin'
    alf_probe_dir = '/Users/gaelle/Downloads/FlatIron/mainenlab/Subjects/ZM_2407/2019-11-05/003/alf/probe_00'

# -- Get spks and clusters
spks = aio.load_object(alf_probe_dir, 'spikes')
clstrs = aio.load_object(alf_probe_dir, 'clusters')

# Fig 1 -- ALL UNITS
# Create a bar plot of the variances of the spike amplitudes for each unit.
fig, var_vals, p_vals = bb.plot.feat_vars(spks)

# Fig 2 -- SINGLE UNIT
# Plot cutoff line indicating the fraction of spikes missing from a unit based on the recorded
#  unit's spike amplitudes, assuming the distribution of the unit's spike amplitudes is symmetric.
fig, fraction_missing = bb.plot.missed_spikes_est(spks, 1)

# Fig 3 -- SINGLE UNIT
# Compare first and last 100 spike waveforms for unit1, across 20 channels around the channel
# of max amplitude, and compare the first and last 50 spike waveforms for unit2, across 15
# channels around the mean.
fig1, wf1, wf2 = bb.plot.single_unit_wf_comp(ephys_file_path, spks, clstrs, unit=1)

# -- Fig 4 -- SINGLE UNIT
# Get a units bunch, and plot waveforms for unit2 from the first to second minute
# across 15 channels.
units = bb.processing.get_units_bunch(spks, ['times'])
ts1 = units['times']['2'][:50]
ts2 = units['times']['2'][-50:]
fig2, wf1_2, wf2_2 = bb.plot.single_unit_wf_comp(ephys_file_path, spks, clstrs, unit=1, ts1=ts1,
                                                 ts2=ts2)
