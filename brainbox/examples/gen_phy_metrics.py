"""
Module for generating single unit metrics for phy.

Ensure you are on 'ibllib@brainbox'.
"""

import time
from pathlib import Path
import numpy as np
import pandas as pd
import brainbox as bb
import alf.io as aio


def gen_metrics(alf_dir, ks_dir, ephys_file_path=None):
    """
    Tries to generate single unit metrics for all units metric-by-metric and save the metrics
    as .tsv files, and displays an error if unable to create one of the metric .tsv files,
    before continuing to the next one.

    Parameters
    ----------
    alf_dir : string
        Full path to alf output directory.
    ks_dir : string
        Full path to the ks2 output directory. The .tsv files will be saved here.
    ephys_file_path : string (optional)
        Full path to binary ephys file.

    Returns
    -------
    units_missing_metrics : set
        Set of units for which not all metrics were able to be calculated.

    Examples
    -------
    1) Create an alf directory from a ks2 output directory. The alf directory cannot be the same as
    the ks2 output directory. Then, generate all metrics that don't require raw ephys data.
        >>> import ibllib.ephys.spikes as e_spks
        >>> from gen_phy_metrics import gen_metrics
        >>> e_spks.ks2_to_alf(ks_dir_full_path, alf_dir_full_path)
        >>> gen_metrics(alf_dir, ks_dir)

    2) Generate metrics from an alf directory and metrics that require an ephys_file_path. For phy,
    the ephys file should be in `ks_dir`.
        >>> from gen_phy_metrics import gen_metrics
        >>> gen_metrics(alf_dir, ks_dir, ephys_file_path=ks_dir)
    """

    # Setup #
    # ----- #

    # Extract alf objects from `alf_dir` and get units info
    alf_dir = Path(alf_dir)
    if not (Path.exists(alf_dir)):
        raise FileNotFoundError('The given alf directory {} does not exist!'.format(alf_dir))

    spks_b = aio.load_object(alf_dir, 'spikes')
    clstrs_b = aio.load_object(alf_dir, 'clusters')
    units_b = bb.processing.get_units_bunch(spks_b)
    units = list(units_b.amps.keys())
    n_units = np.max(spks_b.clusters) + 1

    # Initialize metrics
    cum_amp_drift = np.full((n_units,), np.nan)
    cum_depth_drift = np.full((n_units,), np.nan)
    cv_amp = np.full((n_units,), np.nan)
    cv_fr = np.full((n_units,), np.nan)
    frac_isi_viol = np.full((n_units,), np.nan)
    fn_est = np.full((n_units,), np.nan)
    fp_est = np.full((n_units,), np.nan)
    pres_ratio = np.full((n_units,), np.nan)
    pres_ratio_std = np.full((n_units,), np.nan)
    ptp_sigma = np.full((n_units,), np.nan)

    units_missing_metrics = set()

    # Compute metrics #
    # --------------- #

    # Iterate over all units
    for unit in units:
        if unit == units[0]:
            t0 = time.perf_counter()  # used for computation time estimate

        # Need timestamps, amps, depths
        ts = units_b['times'][unit]
        #Bug was below: amps and depths were defined as units_b['times'][unit]!
        amps = units_b['amps'][unit]
        depths = units_b['depths'][unit]

        # Cumulative drift of spike amplitudes, normalized by total number of spikes.
        try:
            cum_amp_drift[int(unit)] = bb.metrics.cum_drift(amps)
        except Exception as err:
            print("Failed to compute 'cum_drift(amps)' for unit {}. Details: \n {}"
                  .format(unit, err))
            units_missing_metrics.add(unit)

        # Cumulative drift of spike depths, normalized by total number of spikes.
        try:
            cum_depth_drift[int(unit)] = bb.metrics.cum_drift(depths)
        except Exception as err:
            print("Failed to compute 'cum_drift(depths)' for unit {}. Details: \n {}"
                  .format(unit, err))
            units_missing_metrics.add(unit)

        # Coefficient of variation of spike amplitudes.
        try:
            cv_amp[int(unit)] = np.std(amps) / np.mean(amps)
        except Exception as err:
            print("Failed to compute 'cv_amp' for unit {}. Details: \n {}".format(unit, err))
            units_missing_metrics.add(unit)

        # Coefficient of variation of computed instantaneous firing rate.
        try:
            fr = bb.singlecell.firing_rate(ts, hist_win=0.01, fr_win=0.25)
            cv_fr[int(unit)] = np.std(fr) / np.mean(fr)
        except Exception as err:
            print("Failed to compute 'cv_fr' for unit {}. Details: \n {}".format(unit, err))
            units_missing_metrics.add(unit)

        # Fraction of isi violations.
        try:
            frac_isi_viol[int(unit)], _, _ = bb.metrics.isi_viol(ts, rp=0.002)
        except Exception as err:
            print("Failed to compute 'frac_isi_viol' for unit {}. Details: \n {}"
                  .format(unit, err))
            units_missing_metrics.add(unit)

        # Estimated fraction of missing spikes.
        try:
            fn_est[int(unit)], _, _ = bb.metrics.missed_spikes_est(
                amps, spks_per_bin=10, sigma=4, min_num_bins=50)
        except Exception as err:
            print("Failed to compute 'missed_spikes_est' for unit {}. Details: \n {}"
                  .format(unit, err))
            units_missing_metrics.add(unit)

        # Estimated fraction of false positives.
        try:
            fp_est[int(unit)] = bb.metrics.contamination_est(ts, rp=0.002)
        except Exception as err:
            print("Failed to compute 'contamination_est' for unit {}. Details: \n {}".format(unit, err))
            units_missing_metrics.add(unit)

        # Presence ratio
        try:
            pres_ratio[int(unit)], _ = bb.metrics.pres_ratio(ts, hist_win=10)
        except Exception as err:
            print("Failed to compute 'pres_ratio' for unit {}. Details: \n {}".format(unit, err))
            units_missing_metrics.add(unit)

        # Presence ratio over the standard deviation of spike counts in each bin
        try:
            pr, pr_bins = bb.metrics.pres_ratio(ts, hist_win=10)
            pres_ratio_std[int(unit)] = pr / np.std(pr_bins)
        except Exception as err:
            print("Failed to compute 'pres_ratio_std' for unit {}. Details: \n {}"
                  .format(unit, err))
            units_missing_metrics.add(unit)

        # The mean peak-to-peak value over the background noise of the channel of max amplitude.
        if ephys_file_path:
            try:
                ch = clstrs_b['channels'][int(unit)]  # channel of max amplitude
                ptp_sigma[int(unit)] = bb.metrics.ptp_over_noise(
                    ephys_file_path, ts, ch, t=2.0, sr=30000, n_ch_probe=385,
                    dtype='int16', car=False)
            except Exception as err:
                print("Failed to compute 'ptp_sigma' for unit {}. Details: \n {}"
                      .format(unit, err))
                units_missing_metrics.add(unit)

        if unit == units[0]:  # give time estimate
            dt = time.perf_counter() - t0
            print('\nComputing metrics. Estimated time is {:.2f} mins\n'
                  .format(len(units) * dt / 60))

    # Extract to .tsv files #
    # --------------------- #

    try:
        df_cum_amp_drift = pd.DataFrame(cum_amp_drift.round(2))
        df_cum_amp_drift.to_csv(Path(ks_dir, 'cum_amp_drift.tsv'),
                                sep='\t', header=['cum_amp_drift'])
    except Exception as err:
        print("Could not save 'cum_amp_drift' to .tsv. Details: \n {}".format(err))

    try:
        df_cum_depth_drift = pd.DataFrame(cum_depth_drift.round(2))
        df_cum_depth_drift.to_csv(Path(ks_dir, 'cum_depth_drift.tsv'),
                                  sep='\t', header=['cum_depth_drift'])
    except Exception as err:
        print("Could not save 'cum_depth_drift' to .tsv. Details: \n {}".format(err))

    try:
        df_cv_amp = pd.DataFrame(cv_amp.round(2))
        df_cv_amp.to_csv(Path(ks_dir, 'cv_amp.tsv'),
                         sep='\t', header=['cv_amp'])
    except Exception as err:
        print("Could not save 'cv_amp' to .tsv. Details: \n {}".format(err))

    try:
        df_cv_fr = pd.DataFrame(cv_fr.round(2))
        df_cv_fr.to_csv(Path(ks_dir, 'cv_fr.tsv'),
                        sep='\t', header=['cv_fr'])
    except Exception as err:
        print("Could not save 'cv_fr' to .tsv. Details: \n {}".format(err))

    try:
        df_frac_isi_viol = pd.DataFrame(frac_isi_viol.round(2))
        df_frac_isi_viol.to_csv(Path(ks_dir, 'frac_isi_viol.tsv'),
                                sep='\t', header=['frac_isi_viol'])
    except Exception as err:
        print("Could not save 'frac_isi_viol' to .tsv. Details: \n {}".format(err))

    try:
        df_fn_est = pd.DataFrame(fn_est.round(2))
        df_fn_est.to_csv(Path(ks_dir, '     missed_spikes_est.tsv'), sep='\t', header=['missed_spikes_est'])
    except Exception as err:
        print("Could not save 'missed_spikes_est' to .tsv. Details: \n {}".format(err))

    try:
        df_fp_est = pd.DataFrame(fp_est.round(2))
        df_fp_est.to_csv(Path(ks_dir, 'contamination_est.tsv'),
                         sep='\t', header=['contamination_est'])
    except Exception as err:
        print("Could not save 'contamination_est' to .tsv. Details: \n {}".format(err))

    try:
        df_pres_ratio = pd.DataFrame(pres_ratio.round(2))
        df_pres_ratio.to_csv(Path(ks_dir, 'pres_ratio.tsv'),
                             sep='\t', header=['pres_ratio'])
    except Exception as err:
        print("Could not save 'pres_ratio' to .tsv. Details: \n {}".format(err))

    try:
        df_pres_ratio_std = pd.DataFrame(pres_ratio_std.round(2))
        df_pres_ratio_std.to_csv(Path(ks_dir, 'pres_ratio_std.tsv'),
                                 sep='\t', header=['pres_ratio_std'])
    except Exception as err:
        print("Could not save 'pres_ratio_std' to .tsv. Details: \n {}".format(err))

    if ephys_file_path:
        try:
            df_ptp_sigma = pd.DataFrame(ptp_sigma.round(2))
            df_ptp_sigma.to_csv(Path(ks_dir, 'ptp_sigma.tsv'),
                                sep='\t', header=['ptp_sigma'])
        except Exception as err:
            print("Could not save 'cum_amp_drift' to .tsv. Details: \n {}".format(err))

    return units_missing_metrics
