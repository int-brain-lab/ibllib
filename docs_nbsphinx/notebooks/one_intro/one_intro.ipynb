{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use ONE to load and perform some simple analysis on IBL behavioural data. In particular we will cover the following concepts\n",
    "- Using One to search for and download data\n",
    "- \n",
    "\n",
    "This tutorial assumes that you have setup the unified ibl environment and authorised access to IBL data through ONE. If not please follow the previous steps of this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by importing ONE and setting up a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oneibl.one import ONE\n",
    "one = ONE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to look at behavioural data for a subject in a given lab. Let's see which labs we can choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.list(None, 'labs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the cortex lab. To find which subjects are available we will use the one.alyx.rest command. For more information about this useful command please see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_info = one.alyx.rest('subjects', 'list', lab='cortexlab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many subjects have been assigned to the cortex lab and also examine the content of the first item in subj_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subj_info))\n",
    "subj_info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a total of (insert here) subjects in the cortex lab. Each entry in the list subj_info is a dictionary that contains the details about this subject, including the nickname, whether the subject is alive or dead, the gender of the subject. We are interested in finding out the possible subject nicknames so we can refine our search. We can quickly iterate over all items in the subj_info list and extract the subject nicknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_names = [subj['nickname'] for subj in subj_info]\n",
    "print(subject_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose subject KS022 for further analysis and find all the sessions for this subject using the one.search command\n",
    ">**NOTE** we restrict by task_protocol to find the sessions that only have training data, we could also restrict by 'biased' or 'ephys' to only search for sessions where the subject was in phase2 of trainng or when performing the task during with recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eids, sess_info = one.search(subject='KS022', task_protocol='training', details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By returning the session information for each eid we can extract the date and order our experiment ids by date (or training days). Let's first look at the content of one of the sess_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this contains information about the session, including the date, the subject, we can quickly collect the dates for all the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_date = [sess['start_time'] for sess in sess_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dates are returned wi, for convenienve let's reverse the list so that the first training session day is at index 0, for consistency we must reverse the list of eids as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_date.reverse()\n",
    "eids.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by looking at data for the first training day. Let's list what datasets are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid_day1 = eids[0]\n",
    "one.list(eid=eid_day1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we are interested in the in the trials dataset that contains information about the performance of the subject on the task. We can define a list of all the data set types we want to load, for example and download these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_types = ['trials.choice',\n",
    "           'trials.contrastLeft']\n",
    "_ = one.load(eid=eid_day1, dataset_types=d_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can take advantage of the ALF file format and download all files that have the prefix trials. \n",
    ">**NOTE** This would be called loading all attributes associated with the trials object. See here for more information on the ALF file naming convention that the IBL uses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will use a slightly different loading function one.load_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_object = 'trials'\n",
    "_ = one.load_object(eid=eid_day1, obj= d_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the path where the data has been downloaded using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = one.path_from_eid(eid_day1)\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ibllib contains a useful set of functions contained in alf that can be used to read in alf objects. Let's import this module and load in all data associated with the trials object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alf.io as aio\n",
    "from pathlib import Path\n",
    "\n",
    "alf_path = Path(data_path, 'alf')\n",
    "\n",
    "trials_day1 = aio.load_object(alf_path, '_ibl_trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**By using trials_day1 = one.load(eid=eid, data_types=dtypes) we could have automatically loaded in the trials object into memory after downloading the files. Here we have chosen to read in the data after downloading to introduce the useful functions such one.path_from_eid and alf.io.load_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the content of the trials object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trials_day1.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find how many trials there were in the session by inspecting the length of one of the attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_day1 = len(trials_day1.choice)\n",
    "print(n_trials_day1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE** We chose to look at the first attribute of trials oject to find the no. of trials, but we could have looked at the lenght of any of the attributes and got the same results. This is another conswquency of the ALF file format. All attributes associated with a given object will have the same number of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the visual stimulus contrasts that were presented to the subject on day 1. For this we will inspect trials.constrastLeft dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_day1.contrastLeft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three values 1 which indicates a 100 % contrast, 0.5 which indicates a 50 % contrast and whole load of nans....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect trials.contrastRight we will find that all the indices that contain nans in the trials.contrastLeft are filled in trials.contrastRight. Similarly, the opposite is true, all indices with nan values in trials.contrastRight are filled in trials.contrastLeft. Nans basically indicate that the contrast was show on the oppisite side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets combine trials.contrastLeft and trials.contrastRight into a new dataset called trials.contrast. By convetion in the IBL, contrasts that appear on the left are denoted to be negative while those on the right are positive. Let's also reflect this convention when forming our new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trials_day1.contrast = np.empty((n_trials_day1))\n",
    "contrastRight_idx = np.where(~np.isnan(trials_day1.contrastRight))[0]\n",
    "contrastLeft_idx = np.where(~np.isnan(trials_day1.contrastLeft))[0]\n",
    "\n",
    "trials_day1.contrast[contrastRight_idx] = trials_day1.contrastRight[contrastRight_idx]\n",
    "trials_day1.contrast[contrastLeft_idx] = -1 * trials_day1.contrastLeft[contrastLeft_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect how many of each type of contrast was presented to the subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts, n_contrasts = np.unique(trials_day1.contrast, return_counts=True)\n",
    "print(contrasts)\n",
    "print(n_contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's look at how the mouse performed. This information is stored in the feedbackType attribute of the trials object. A positive feedback of +1 means the mouse got the task correct, whereas a feedback of -1 means the mouse got the trial wrong. Let's double check that these are the only values we see in trials.feedbakType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(trials_day1.feedbackType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily compute how well the mouse performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.sum(trials_day1.feedbackType == 1)/ n_trials_day1\n",
    "incorrect =  np.sum(trials_day1.feedbackType == -1)/ n_trials_day1\n",
    "print(correct * 100)\n",
    "print(incorrect * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected on the first day of training the mouse performed at chance level and was probably just guessing. Let's break down the performance at each contrast level and create a simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "contrast_performance = np.empty((contrasts.size))\n",
    "for ic, c in enumerate(contrasts):\n",
    "    contrast_idx = np.where(trials_day1.contrast == c)[0]\n",
    "    contrast_performance[ic] = np.sum(trials_day1.feedbackType[contrast_idx] == 1) / contrast_idx.shape[0]\n",
    "\n",
    "  \n",
    "plt.plot(contrasts * 100, contrast_performance * 100)\n",
    "plt.scatter(contrasts * 100, contrast_performance * 100)\n",
    "plt.ylim([0,100])\n",
    "plt.xticks([*(contrasts * 100)])\n",
    "plt.xlabel('Stimulus Contrast (%)')\n",
    "plt.ylabel('Performance (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the mice learns the task we expect its performance to improve. Let's repeat the steps above and see how the same mouse performaed on day 20 of trainng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid_day20 = eids[14]\n",
    "trials_day20 = one.load_object(eid=eid_day20, obj=d_object)\n",
    "n_trials_day20 = len(trials_day20.choice)\n",
    "\n",
    "trials_day20.contrast = np.empty((n_trials_day20))\n",
    "contrastRight_idx = np.where(~np.isnan(trials_day20.contrastRight))[0]\n",
    "contrastLeft_idx = np.where(~np.isnan(trials_day20.contrastLeft))[0]\n",
    "\n",
    "trials_day20.contrast[contrastRight_idx] = trials_day20.contrastRight[contrastRight_idx]\n",
    "trials_day20.contrast[contrastLeft_idx] = -1 * trials_day20.contrastLeft[contrastLeft_idx]\n",
    "\n",
    "contrasts, n_contrasts = np.unique(trials_day20.contrast, return_counts=True)\n",
    "print(contrasts)\n",
    "print(n_contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how on day 20 the mouse has not only has trials with 100 and 50 % visual stimuli contrast but also . This follows the IBL training protocol where harder contrasts are introduced as the mouse becomes more expert at the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.sum(trials_day20.feedbackType == 1)/ n_trials_day20\n",
    "incorrect =  np.sum(trials_day20.feedbackType == -1)/ n_trials_day20\n",
    "print(correct * 100)\n",
    "print(incorrect * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance has vastly improved compared to day 1. We can see the mouse is no longer performing at chance level. Once again let's break this down further into the performance on individual contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_performance = np.empty((contrasts.size))\n",
    "for ic, c in enumerate(contrasts):\n",
    "    contrast_idx = np.where(trials_day20.contrast == c)[0]\n",
    "    contrast_performance[ic] = np.sum(trials_day20.feedbackType[contrast_idx] == 1) / contrast_idx.shape[0]\n",
    "\n",
    "  \n",
    "plt.plot(contrasts * 100, contrast_performance * 100)\n",
    "plt.scatter(contrasts * 100, contrast_performance * 100)\n",
    "plt.ylim([0,100])\n",
    "plt.xticks([*(contrasts * 100)])\n",
    "plt.xlabel('Stimulus Contrast (%)')\n",
    "plt.ylabel('Performance (%)')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the y axis , this follows the shape of the pyschometric curve that is used in IBL data trainign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts_performance_rightward = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other interesting plots can we do with this data?\n",
    "- Try plotting reaction time as with contrast\n",
    "- Try the intervals between tasks. Do you notice that toward the end of the session, the mouse is becoming less engaged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be familiar with the basics of how to see load data with one and how to analyse the output from task. Let's now extend our understanding of ONE and the ALF format and combine electrophysiology data with behavioural data. Alternatively, you can replicate everything in this tutorial but using the datajoint approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iblenv_testing] *",
   "language": "python",
   "name": "conda-env-iblenv_testing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}