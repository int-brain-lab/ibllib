from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

import alf.io

from ibllib.io.extractors import training_audio as audio

main_path = '/mnt/s0/Data/Subjects'

# step 1 is to launch the extraction on audio
for wfile in Path(main_path).rglob('*.wav'):
    print(wfile)
    ses_path = wfile.parents[1]
    audio.extract_sound(ses_path, save=True)

# step 2 plot the result - here for the last session only
D = alf.io.load_object(ses_path / 'alf', 'audioSpectrogram')

cues = alf.io.load_object(ses_path / 'alf', 'audioOnsetGoCue',
                          attribute='times', timescale='microphone')
tlims = D['times_microphone'][[0, -1]].flatten()
flims = D['frequencies'][0, [0, -1]].flatten()

fig = plt.figure(figsize=[16, 7])
ax = plt.axes()

im = ax.imshow(20 * np.log10(D['power'].T), aspect='auto', cmap=plt.get_cmap('magma'),
               extent=np.concatenate((tlims, flims)), origin='lower')
ax.plot(cues['times_microphone'], cues['times_microphone'] * 0 + 5000, '*k')
ax.set_xlabel(r'Time (s)')
ax.set_ylabel(r'Frequency (Hz)')
plt.colorbar(im)
im.set_clim(-100, -60)

sns.set_style("whitegrid")
db_q = 20 * np.log10(np.percentile(D['power'], [10, 90], axis=0))
plt.figure()
ax = plt.axes()
ax.plot(D['frequencies'].flatten(), 20 * np.log10(np.median(D['power'], axis=0)), label='median')
ax.plot(D['frequencies'].flatten(), 20 * np.log10(np.mean(D['power'], axis=0)), label='average')
ax.fill_between(D['frequencies'].flatten(), db_q[0, :], db_q[1, :], alpha=0.5)
ax.set_ylabel(r'dBFS')
ax.set_xlabel(r'Frequency (Hz)')
