{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Turn off logging and disable tqdm this is a hidden cell on docs page\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger('ibllib')\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "# Download the public datasets\n",
    "\n",
    "To get a feel for the structure of the data we recommended first downloading the alf data for a single repeated site session and exploring how the data is stored locally on disk. An example alf folder can be downloaded from [here](https://ibl-brain-wide-map-public.s3.amazonaws.com/sample_data/mainenlab/Subjects/ZM_2241/2020-01-30/001/alf_ZM2241_2020-01-30_001.zip). Documentation explaining the data structure can be found [here](https://int-brain-lab.github.io/iblenv/notebooks_external/data_structure.html).\n",
    "\n",
    "In the following sections, we explain how to use the [ONE-api](https://int-brain-lab.github.io/ONE/) to search for and download datasets for any session released. Using the ONE-api is the recommended method to browse through and download available datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "### Environment\n",
    "To use IBL data you will need a python environment with python > 3.10, although Python 3.12 is recommended. To create a new environment from scratch you can install [anaconda](https://www.anaconda.com/products/distribution#download-section) and follow the instructions below to create a new python environment (more information can also be found [here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html))\n",
    "\n",
    "```\n",
    "conda create --name ibl python=3.12\n",
    "```\n",
    "Make sure to always activate this environment before installing or working with the IBL data\n",
    "```\n",
    "conda activate ibl\n",
    "```\n",
    "\n",
    "### Install packages\n",
    "\n",
    "To use IBL data you will need to install the ONE-api package. We also recommend installing ibllib. These can be installed via pip.\n",
    "```python\n",
    "pip install ONE-api\n",
    "pip install ibllib\n",
    "```\n",
    "\n",
    "### Setting up credentials\n",
    "Credentials can be setup in a python terminal in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.api import ONE\n",
    "\n",
    "ONE.setup(base_url='https://openalyx.internationalbrainlab.org', silent=True)\n",
    "one = ONE(password='international')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore and download data using the ONE-api\n",
    "\n",
    "### Useful links\n",
    "To get a good understanding of the ONE-api and the various methods available we recommend working through these tutorials.\n",
    "\n",
    "* [ONE quickstart](https://int-brain-lab.github.io/iblenv/notebooks_external/one_quickstart.html)\n",
    "* [Searching with ONE](https://int-brain-lab.github.io/ONE/notebooks/one_search/one_search.html)\n",
    "* [Listing with ONE](https://int-brain-lab.github.io/ONE/notebooks/one_list/one_list.html)\n",
    "* [Loading with ONE](https://int-brain-lab.github.io/ONE/notebooks/one_load/one_load.html)\n",
    "* [ONE Alyx REST API](https://int-brain-lab.github.io/ONE/notebooks/one_advanced/one_advanced.html) (advanced)\n",
    "\n",
    "Further examples are given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the ONE-api\n",
    "Prior to do any searching / downloading, you need to instantiate ONE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.api import ONE\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all sessions available\n",
    "Once ONE is instantiated, you can use the REST ONE-api to list all sessions publicly available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = one.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each session is given a unique identifier (eID); this eID is what you will use to download data for a given session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each session is represented by a unique experiment id (eID)\n",
    "print(sessions[0],)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Find recordings of a specific brain region\n",
    "If we are interested in a given brain region, we can use the `search_insertions` method to find all recordings associated with that region. For example, to find all recordings associated with the **Rhomboid Nucleus (RH)** region of the thalamus."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# this is the query that yields the few recordings for the Rhomboid Nucleus (RH) region\n",
    "insertions_rh = one.search_insertions(atlas_acronym='RH', datasets='spikes.times.npy', project='brainwide')\n",
    "\n",
    "# if we want to extend the search to all thalamic regions, we can do the following\n",
    "insertions_th = one.search_insertions(atlas_acronym='TH', datasets='spikes.times.npy', project='brainwide')\n",
    "\n",
    "# the Allen brain regions parcellation is hierarchical, and searching for Thalamus will return all child Rhomboid Nucleus (RH) regions\n",
    "assert set(insertions_rh).issubset(set(insertions_th))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a session that has a dataset of interest\n",
    "Not all sessions will have all the datasets available. As such, it may be important for you to filter and search for only sessions with particular datasets of interest.\n",
    "The detailed list of datasets can be found in this [document](https://docs.google.com/document/d/1OqIqqakPakHXRAwceYLwFY9gOrm8_P62XIfCTnHwstg/edit#).\n",
    "\n",
    "In the example below, we want to find all sessions that have `spikes.times` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sessions that have spikes.times datasets\n",
    "sessions_with_spikes = one.search(project='brainwide', dataset='spikes.times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Click here](https://int-brain-lab.github.io/ONE/notebooks/one_search/one_search.html) for a complete guide to searching using ONE.\n",
    "\n",
    "\n",
    "### Find data associated with a release or publication\n",
    "Datasets are often associated to a publication, and are tagged as such to facilitate reproducibility of analysis. You can list all tags and their associated publications like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and print all tags in the public database\n",
    "tags = {t['name']: t['description'] for t in one.alyx.rest('tags', 'list') if t['public']}\n",
    "for key, value in tags.items():\n",
    "    print(f\"{key}\\n{value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the tag to restrict your searches to a specific data release and as a filter when browsing the public database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Note that tags are associated with datasets originally\n",
    "# You can load a local index of sessions and datasets associated with a specific data release\n",
    "one.load_cache(tag='2022_Q2_IBL_et_al_RepeatedSite')\n",
    "sessions_rep_site = one.search()  # All sessions used in the repeated site paper\n",
    "\n",
    "# Find insertions that are tagged\n",
    "# (you do not have access to the tag endpoint from the insertion list, so you need to create a django query)\n",
    "ins_str_query = 'datasets__tags__name,2022_Q2_IBL_et_al_RepeatedSite'\n",
    "insertions_rep_site = one.alyx.rest('insertions', 'list', django=ins_str_query)\n",
    "\n",
    "# To return to the full cache containing an index of all IBL experiments\n",
    "ONE.cache_clear()\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data using the ONE-api\n",
    "Once sessions of interest are identified with the unique identifier (eID), all files ready for analysis are found in the **alf** collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find an example session with data\n",
    "eid, *_ = one.search(project='brainwide', dataset='alf/')\n",
    "# List datasets associated with a session, in the alf collection\n",
    "datasets = one.list_datasets(eid, collection='alf*')\n",
    "\n",
    "# Download all data in alf collection\n",
    "files = one.load_collection(eid, 'alf', download_only=True)\n",
    "\n",
    "# Show where files have been downloaded to\n",
    "print(f'Files downloaded to {files[0].parent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the spike sorting data we need to find out which probe label (`probeXX`) was used for this session. This can be done by finding the probe insertion associated with this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find an example session with spike data\n",
    "# Note: Restricting by task and project makes searching for data much quicker\n",
    "eid, *_ = one.search(project='brainwide', dataset='spikes', task='ephys')\n",
    "\n",
    "# Data for each probe insertion are stored in the alf/probeXX folder.\n",
    "datasets = one.list_datasets(eid, collection='alf/probe*')\n",
    "probe_labels = set(d.split('/')[1] for d in datasets)  # List the insertions\n",
    "\n",
    "# You can find full details of a session's insertions using the following database query:\n",
    "insertions = one.alyx.rest('insertions', 'list', session=eid)\n",
    "probe_labels = [ins['name'] for ins in insertions]\n",
    "\n",
    "files = one.load_collection(eid, f'alf/{probe_labels[0]}/pykilosort', download_only=True)\n",
    "\n",
    "# Show where files have been downloaded to\n",
    "print(f'Files downloaded to {files[0].parent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading different objects\n",
    "\n",
    "To load in the data we can use some of the following loading methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load in all trials datasets\n",
    "trials = one.load_object(eid, 'trials', collection='alf')\n",
    "\n",
    "# Load in a single wheel dataset\n",
    "wheel_times = one.load_dataset(eid, '_ibl_wheel.timestamps.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples for loading different objects can be found in the following tutorials [here](https://int-brain-lab.github.io/iblenv/loading_examples.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced examples\n",
    "#### Example 1: Searching for sessions from a specific lab\n",
    "Let's imagine you are interested in obtaining the data from a given lab, that was part of the Reproducible Ephys data release.\n",
    "If you want to use data associated to a given lab only, you could simply query for the whole dataset as shown above, and filter `sessions_rep_site` for the key \"lab\" of a given value, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "one.load_cache(tag='2022_Q2_IBL_et_al_RepeatedSite')\n",
    "sessions_lab = one.search(lab='mrsicflogellab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you wanted to query only the data for a given lab, it might be most judicious to first\n",
    "know the list of all labs available, select an arbitrary lab name from it, and query the specific sessions from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# List details of all sessions (returns a list of dictionaries)\n",
    "_, det = one.search(details=True)\n",
    "labs = set(d['lab'] for d in det)  # Get the set of unique labs\n",
    "\n",
    "# Example lab name\n",
    "lab_name = list(labs)[0]\n",
    "\n",
    "# Searching for RS sessions with specific lab name\n",
    "sessions_lab = one.search(dataset='spikes', lab=lab_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also get this list, using [one.alyx.rest](https://int-brain-lab.github.io/ONE/notebooks/one_advanced/one_advanced.html), however it is a little slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of labs (and all metadata information associated)\n",
    "labs = one.alyx.rest('labs', 'list',\n",
    "                     django='session__data_dataset_session_related__tags__name,2022_Q2_IBL_et_al_RepeatedSite')\n",
    "# Note the change in the django filter compared to searching over 'sessions'\n",
    "\n",
    "# Example lab name\n",
    "lab_name = labs[0]['name']  # e.g. 'mrsicflogellab'\n",
    "\n",
    "# Searching for RS sessions with specific lab name\n",
    "sessions_lab = one.alyx.rest('sessions', 'list', dataset_types='spikes.times', lab=lab_name,\n",
    "                             tag='2022_Q2_IBL_et_al_RepeatedSite')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
