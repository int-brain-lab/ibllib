{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f26f839",
   "metadata": {},
   "source": [
    "# Loading Widefield Imaging Data\n",
    "\n",
    "Imaging data recorded using widefield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a17c3a",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Turn off logging and disable tqdm this is a hidden cell on docs page\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger('ibllib')\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135569e0",
   "metadata": {},
   "source": [
    "## Relevant ALF objects\n",
    "* imaging\n",
    "* imagingLightSource\n",
    "* widefieldU\n",
    "* widefieldSVT\n",
    "* widefieldChannels\n",
    "* widefieldLandmark\n",
    "\n",
    "\n",
    "## Widefield pipeline\n",
    "Widefield data collected in the IBL has been collected and processed following the pipeline described by [Couto et al](10.1038/s41596-021-00527-z). Briefly the raw data (imaging.frames.mov) has undergone motion and baseline correction followed by denoising and decomposition (SVD) resulting in a compressed image stack formed of the spatial components (widefieldU.images.npy) and the temporal components (widefeildlSVT.uncorrected.npy). Haemodynamic correction has also been applied yielding corrected temporal components (widefieldSVT.haemoCorrected.npy).\n",
    "\n",
    "\n",
    "## More details\n",
    "* [Description of widefield datasets](https://docs.google.com/document/d/1OqIqqakPakHXRAwceYLwFY9gOrm8_P62XIfCTnHwstg/edit#heading=h.7f0skb6ow9gw)\n",
    "* [Description of imaging datasets](https://docs.google.com/document/d/1OqIqqakPakHXRAwceYLwFY9gOrm8_P62XIfCTnHwstg/edit#heading=h.5d32zs4grdoy)\n",
    "\n",
    "\n",
    "## Relevant packages\n",
    "Please install the wfield package to work with widefield data\n",
    "```python\n",
    "pip install git+https://github.com/jcouto/wfield.git\n",
    "```\n",
    "We encourage you to look at futher examples and tutorials that are available in the [wfield github repo](https://github.com/jcouto/wfield/tree/master).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fda936",
   "metadata": {},
   "source": [
    "## Finding sessions with widefield data\n",
    "Sessions that contain widefield data can be found by searching for sessions with a corresponding widefield dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe38dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.api import ONE\n",
    "one = ONE()\n",
    "sessions = one.search(datasets='widefieldU.images.npy')\n",
    "print(f'{len(sessions)} sessions with widefield data found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db50e11",
   "metadata": {},
   "source": [
    "## Loading widefield imaging stack data\n",
    "The imaging stack can be reconstructed from the decomponsed spatial and temporal components of the SVD. The imaging stack contains the imaging data for each frame in the session and has dimensions (nFrames, nx, ny) where `nx` is the width of the imaging window, and `ny` the height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfield\n",
    "\n",
    "# Choose the first session\n",
    "eid = sessions[0]\n",
    "# Load the spatial components\n",
    "U = one.load_dataset(eid, 'widefieldU.images.npy')\n",
    "# Load the haemocorrected temporal components\n",
    "SVT = one.load_dataset(eid, 'widefieldSVT.haemoCorrected.npy')\n",
    "# Use wfield package to build imaging stack\n",
    "stack = wfield.SVDStack(U, SVT)\n",
    "\n",
    "print(f'Dimensions of imaging stack: {stack.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34aec7",
   "metadata": {},
   "source": [
    "## Aligning data to the Allen reference atlas\n",
    "We can register the imaging stack to the Allen reference atlas using the landmark file that contains the bregma and lambda position in the imaging window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmark_file = one.load_dataset(eid, 'widefieldLandmarks.dorsalCortex.json', download_only=True)\n",
    "landmarks = wfield.load_allen_landmarks(lmark_file)\n",
    "# Warp and register the image stack to the Allen dorsal cortex\n",
    "stack.set_warped(True, M=landmarks['transform'])\n",
    "\n",
    "# plot the data from the 100th frame\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(stack[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875e9cc",
   "metadata": {},
   "source": [
    "## Loading imaging times\n",
    "Timestamps for each frame are in seconds from session start and are aligned to other times from the session, e.g behavioral or video events. The timestamps contain times for both the functional (haemodynamic corrected) and non-functional channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd2afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "times = one.load_dataset(eid, 'imaging.times.npy')\n",
    "channels = one.load_dataset(eid, 'imaging.imagingLightSource.npy')\n",
    "channel_info = one.load_dataset(eid, 'imagingLightSource.properties.htsv', download_only=True)\n",
    "channel_info = pd.read_csv(channel_info)\n",
    "\n",
    "# If haemocorrected need to take timestamps that correspond to functional channel\n",
    "functional_channel = 470\n",
    "functional_chn = channel_info.loc[channel_info['wavelength'] == functional_channel]['channel_id'].values[0]\n",
    "times = times[channels == functional_chn]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
